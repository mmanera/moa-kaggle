{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "moa-chall-train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YO_rhpWK7jtP"
      },
      "source": [
        "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# # For example, here's several helpful packages to load\n",
        "\n",
        "# import numpy as np # linear algebra\n",
        "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# # Input data files are available in the read-only \"../input/\" directory\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Xq_3iUWH7jtU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCCnw2lX9TfE",
        "outputId": "b06bb5f2-f88e-4e1f-902a-c2616847f844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NDLO-u0X7jtY"
      },
      "source": [
        "train_features = pd.read_csv('/content/drive/My Drive/moa/train_features.csv')\n",
        "train_targets_scored = pd.read_csv('/content/drive/My Drive/moa/train_targets_scored.csv')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lXuhUUG8wgh"
      },
      "source": [
        "train_features.dtypes.sort_values()\n",
        "\n",
        "X = train_features.iloc[:, 1:].values\n",
        "y = train_targets_scored.iloc[:, 1:].values"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAP05kHG820B"
      },
      "source": [
        "# oneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UblZ8Ce885o5",
        "outputId": "716e970a-0135-44d1-a97c-ecbd94e47c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "X[:, 0:5]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0, 1.0, 24, 'D1', 1.062],\n",
              "       [0.0, 1.0, 72, 'D1', 0.0743],\n",
              "       [0.0, 1.0, 48, 'D1', 0.628],\n",
              "       ...,\n",
              "       [1.0, 0.0, 48, 'D2', 0.3942],\n",
              "       [0.0, 1.0, 24, 'D1', 0.666],\n",
              "       [0.0, 1.0, 72, 'D1', -0.8598]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbIYQPTu84DZ"
      },
      "source": [
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l39TjDEa87u5",
        "outputId": "dc1c958a-6078-496f-9884-15d3a34bb7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "X[:, 0:5]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, 1.0, 24],\n",
              "       [1.0, 0.0, 0.0, 1.0, 72],\n",
              "       [1.0, 0.0, 0.0, 1.0, 48],\n",
              "       ...,\n",
              "       [0.0, 1.0, 1.0, 0.0, 48],\n",
              "       [1.0, 0.0, 0.0, 1.0, 24],\n",
              "       [1.0, 0.0, 0.0, 1.0, 72]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ4trFxG89I5",
        "outputId": "4084a9d3-287b-4624-e8e5-89a6a04ff9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23814, 877)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BduztvDs8_5h",
        "outputId": "08b098bd-4f2a-4fe2-91c5-112587160e6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0, 0.0, 0.0, ..., 0.2139, 0.3801, 0.4176],\n",
              "       [1.0, 0.0, 0.0, ..., 0.1241, 0.6077, 0.7371],\n",
              "       [1.0, 0.0, 0.0, ..., -0.2187, -1.408, 0.6931],\n",
              "       ...,\n",
              "       [0.0, 1.0, 1.0, ..., 0.7592, 0.6656, 0.3808],\n",
              "       [1.0, 0.0, 0.0, ..., 0.7015, -0.629, 0.074],\n",
              "       [1.0, 0.0, 0.0, ..., -0.4775, -2.15, -4.252]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv_um0ir80qh"
      },
      "source": [
        "# Normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXUjhudq9D7R",
        "outputId": "6edd738f-5ec8-412e-a2c5-e2302084736c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23814, 877)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ETz6lfK9FXZ",
        "outputId": "32b30b0a-5b15-4b3f-ab02-1fa58b5d231c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23814, 206)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOlODXI39HcR",
        "outputId": "2c30ea5c-d431-4bfb-e020-69e7dfdfb9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(877,1024)           \n",
        "        self.fc2 = nn.Linear(1024,206)         \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc1): Linear(in_features=877, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=206, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxmWBsSP8s6g",
        "outputId": "37124fed-93c2-4284-d1fd-2b8a6f8ee22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        }
      },
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss()                       \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "batch_size = 64\n",
        "n_epochs = 100\n",
        "batch_no = len(X) // batch_size                 # batch_no=125, pois 125 * 64 = 8000\n",
        "\n",
        "train_loss = 0\n",
        "train_loss_min = np.Inf\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(batch_no):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        x_var = Variable(torch.FloatTensor(X[start:end]))\n",
        "        y_var = Variable(torch.FloatTensor(y[start:end])) \n",
        "        \n",
        "        \n",
        "        # output = model(x_var)\n",
        "        # loss = loss_fn(output,y_var)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x_var)       \n",
        "        loss = loss_fn(output,y_var)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # values, labels = torch.max(output, 1)\n",
        "        # num_right = np.sum(labels.data.numpy() == y[start:end])\n",
        "        train_loss += loss.item() * batch_size\n",
        "    \n",
        "    train_loss = train_loss / len(X)\n",
        "    if train_loss <= train_loss_min:\n",
        "        print(\"Validation loss decreased ({:6f} ===> {:6f}). Saving the model...\".format(train_loss_min,train_loss))\n",
        "        torch.save(model.state_dict(), \"model.pt\")\n",
        "        train_loss_min = train_loss\n",
        "    \n",
        "    # if epoch % 200 == 0:\n",
        "    #     print('')\n",
        "    #     print(\"Epoch: {} \\tTrain Loss: {} \\tTrain Accuracy: {}\".format(epoch + 1, train_loss))\n",
        "    print(\"Ronaldo\")\n",
        "\n",
        "print('Training Ended! ')\n",
        "\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss decreased (   inf ===> 0.695385). Saving the model...\n",
            "Ronaldo\n",
            "Ronaldo\n",
            "Ronaldo\n",
            "Ronaldo\n",
            "Ronaldo\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-6cc078245ab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
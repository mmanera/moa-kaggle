{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "moa_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "Xq_3iUWH7jtU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hmWPUGWeX3P",
        "outputId": "87e41af1-beb0-4e78-dd67-6f85c02d3623"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NDLO-u0X7jtY"
      },
      "source": [
        "train_features = pd.read_csv('/content/drive/My Drive/moa/train_features.csv')\n",
        "train_targets_scored = pd.read_csv('/content/drive/My Drive/moa/train_targets_scored.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/My Drive/moa/sample_submission.csv')\n",
        "test_features = pd.read_csv('/content/drive/My Drive/moa/test_features.csv')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRbFeNtXo5WP"
      },
      "source": [
        "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
        "CELLS = [col for col in train_features.columns if col.startswith('c-')]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7B5ZmqYar3j",
        "outputId": "a9e85ed6-4bcc-463a-9821-b71e564a61d0"
      },
      "source": [
        "train_features[\"cp_type\"].value_counts()\n",
        "# Can we drop cp_type column? ctl_vehicle is 8% from total."
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "trt_cp         21948\n",
              "ctl_vehicle     1866\n",
              "Name: cp_type, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq7sWS3nwQlr"
      },
      "source": [
        "train = train_features.merge(train_targets_scored, on='sig_id')\n",
        "test = test_features\n",
        "# If we choose to drop train_features[train['cp_type']=='ctl_vehicle'], uncomment.\n",
        "# train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
        "# test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
        "\n",
        "target = train[train_targets_scored.columns]\n",
        "train = train.drop('cp_type', axis=1)               # train[\"cp_type\"].unique() = 'trt_cp'. We cant pass cp_type without encode.\n",
        "train = train.drop('sig_id', axis=1)\n",
        "\n",
        "# target                      # 23814 rows Ã— 207 columns. # Its actually the same as train_targets_scored, if we didnt preprocess anythig."
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3HG4X8ptt8"
      },
      "source": [
        "class MoADataset:\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):              # len() will use the __len__ method if present to get your object for its length.  \n",
        "        return (self.features.shape[0])\n",
        "    \n",
        "    def __getitem__(self, idx):     # docs: https://docs.python.org/3/reference/datamodel.html#object.__getitem__. In this case returns a dict.\n",
        "        dct = { \n",
        "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),       # ex: np_array[0, :] -> [1,2]\n",
        "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
        "        }\n",
        "        return dct\n",
        "    \n",
        "class TestDataset:\n",
        "    def __init__(self, features):\n",
        "        self.features = features\n",
        "        \n",
        "    def __len__(self):\n",
        "        return (self.features.shape[0])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        dct = {\n",
        "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
        "        }\n",
        "        return dct\n",
        "    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA1Xa_9Rp8Hz"
      },
      "source": [
        "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
        "    model.train()\n",
        "    final_loss = 0\n",
        "    \n",
        "    for data in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        inputs, targets = data['x'].to(device), data['y'].to(device)        # Asks for the value of \"x\" and \"y\" keys.\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        \n",
        "        final_loss += loss.item()\n",
        "        \n",
        "    final_loss /= len(dataloader)\n",
        "    \n",
        "    return final_loss   \n",
        "\n",
        "def valid_fn(model, loss_fn, dataloader, device):\n",
        "    model.eval()\n",
        "    final_loss = 0\n",
        "    valid_preds = []\n",
        "    \n",
        "    for data in dataloader:\n",
        "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        \n",
        "        final_loss += loss.item()\n",
        "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
        "        \n",
        "    final_loss /= len(dataloader)\n",
        "    valid_preds = np.concatenate(valid_preds)\n",
        "    \n",
        "    return final_loss, valid_preds"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf8uupETxeol"
      },
      "source": [
        "# process_data(data) uses get_dummies() to create cp_time: 24, 48, 72. cp_dose: D1, D2\n",
        "def process_data(data):\n",
        "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])              \n",
        "   \n",
        "    return data"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3nEUtlOxxVS"
      },
      "source": [
        "# Simply target without id.\n",
        "target_cols = target.drop('sig_id', axis=1).columns.tolist()\n",
        "# We use this comprehension to take into account the dummies created by our process_data()\n",
        "feature_cols = [col for col in process_data(train).columns if col not in target_cols]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sQxSBXotzRb"
      },
      "source": [
        "# HyperParameters\n",
        "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "EPOCHS = 25\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "NFOLDS = 5\n",
        "EARLY_STOPPING_STEPS = 10\n",
        "EARLY_STOP = False\n",
        "\n",
        "num_features=len(feature_cols)\n",
        "num_targets=len(target_cols)\n",
        "hidden_size=1024"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPVBzw_sqIfT"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, num_features, num_targets, hidden_size):\n",
        "        super(Model, self).__init__()\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
        "        \n",
        "        self.batch_norm2 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.dense2 = nn.utils.weight_norm(nn.Linear(hidden_size, hidden_size))\n",
        "        \n",
        "        self.batch_norm3 = nn.BatchNorm1d(hidden_size)\n",
        "        self.dropout3 = nn.Dropout(0.5)\n",
        "        self.dense3 = nn.utils.weight_norm(nn.Linear(hidden_size, num_targets))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.dense1(x))\n",
        "        \n",
        "        x = self.batch_norm2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = F.relu(self.dense2(x))\n",
        "        \n",
        "        x = self.batch_norm3(x)\n",
        "        x = self.dropout3(x)\n",
        "        x = self.dense3(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUb7Yp2Weq9X"
      },
      "source": [
        "folds = train.copy()\n",
        "folds = folds.sample(frac=1).reset_index(drop=True)             # to randomize\n",
        "kf = model_selection.KFold(n_splits=5)\n",
        "for fold, (t_idx, v_idx) in enumerate(kf.split(X=folds)):\n",
        "    folds.loc[v_idx, 'kfold'] = fold\n",
        "folds['kfold'] = folds['kfold'].astype(int)           # Otherwise 0.0, 1.0, 2.0, 3.0...\n",
        "\n",
        "train = process_data(folds)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlLZAAxityeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc21d16b-4e25-495a-acac-36cb2460569f"
      },
      "source": [
        "def run_training(fold):\n",
        "    trn_idx = train[train['kfold'] != fold].index\n",
        "    val_idx = train[train['kfold'] == fold].index\n",
        "\n",
        "    train_df = train[train['kfold'] != fold].reset_index(drop=True)\n",
        "    valid_df = train[train['kfold'] == fold].reset_index(drop=True)\n",
        "\n",
        "    x_train, y_train  = train_df[feature_cols].values, train_df[target_cols].values\n",
        "    x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols].values\n",
        "\n",
        "    train_dataset = MoADataset(x_train, y_train)\n",
        "    valid_dataset = MoADataset(x_valid, y_valid)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)      # It has a len of 187. 187 * 128(BATCH_SIZE) = 23936. Contains the 23814 rows of the train_df.\n",
        "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = Model(\n",
        "        num_features=num_features,\n",
        "        num_targets=num_targets,\n",
        "        hidden_size=hidden_size,\n",
        "    )\n",
        "\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3,\n",
        "                                                max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # oof = np.zeros((len(train), target.iloc[:, 1:].shape[1]))\n",
        "    best_loss = np.inf                  # Represents a positive infinite\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_fn(model, optimizer, scheduler, loss_fn, trainloader, DEVICE)\n",
        "        print(f\"EPOCH: {epoch}, train_loss: {train_loss}\")\n",
        "        valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
        "        print(f\"EPOCH: {epoch}, valid_loss: {valid_loss}\")\n",
        "        \n",
        "        if valid_loss < best_loss:\n",
        "            print(f\"updating best model on Fold={fold}\") \n",
        "            best_loss = valid_loss\n",
        "            # oof[val_idx] = valid_preds\n",
        "            torch.save(model.state_dict(), f\"FOLD{fold}_.pth\")\n",
        "        \n",
        "for run_k_fold in range(5):              # 5 folds\n",
        "    print(run_training(run_k_fold))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0, train_loss: 0.5281370884220072\n",
            "EPOCH: 0, valid_loss: 0.0307204511604811\n",
            "updating best model on Fold=0\n",
            "EPOCH: 1, train_loss: 0.022438783098587253\n",
            "EPOCH: 1, valid_loss: 0.01859385228568786\n",
            "updating best model on Fold=0\n",
            "EPOCH: 2, train_loss: 0.018942339395816694\n",
            "EPOCH: 2, valid_loss: 0.01703095891954083\n",
            "updating best model on Fold=0\n",
            "EPOCH: 3, train_loss: 0.01761286000677403\n",
            "EPOCH: 3, valid_loss: 0.016438989556933705\n",
            "updating best model on Fold=0\n",
            "EPOCH: 4, train_loss: 0.01707520077767588\n",
            "EPOCH: 4, valid_loss: 0.01612557813917336\n",
            "updating best model on Fold=0\n",
            "EPOCH: 5, train_loss: 0.016680718093310426\n",
            "EPOCH: 5, valid_loss: 0.015979137957880373\n",
            "updating best model on Fold=0\n",
            "EPOCH: 6, train_loss: 0.016467317032484\n",
            "EPOCH: 6, valid_loss: 0.015884509971855504\n",
            "updating best model on Fold=0\n",
            "EPOCH: 7, train_loss: 0.01650869666329966\n",
            "EPOCH: 7, valid_loss: 0.01592736299100675\n",
            "EPOCH: 8, train_loss: 0.016497422097213315\n",
            "EPOCH: 8, valid_loss: 0.01596479524711245\n",
            "EPOCH: 9, train_loss: 0.016522424145532934\n",
            "EPOCH: 9, valid_loss: 0.015863747556546803\n",
            "updating best model on Fold=0\n",
            "EPOCH: 10, train_loss: 0.01650827279276896\n",
            "EPOCH: 10, valid_loss: 0.01580058072546595\n",
            "updating best model on Fold=0\n",
            "EPOCH: 11, train_loss: 0.016497985303601963\n",
            "EPOCH: 11, valid_loss: 0.015906772992916797\n",
            "EPOCH: 12, train_loss: 0.016396838852873186\n",
            "EPOCH: 12, valid_loss: 0.015917482418253234\n",
            "EPOCH: 13, train_loss: 0.01631665489192577\n",
            "EPOCH: 13, valid_loss: 0.015783488971034165\n",
            "updating best model on Fold=0\n",
            "EPOCH: 14, train_loss: 0.016210388123439064\n",
            "EPOCH: 14, valid_loss: 0.0156926938920821\n",
            "updating best model on Fold=0\n",
            "EPOCH: 15, train_loss: 0.016155610429810598\n",
            "EPOCH: 15, valid_loss: 0.015570559416358409\n",
            "updating best model on Fold=0\n",
            "EPOCH: 16, train_loss: 0.016073874947958745\n",
            "EPOCH: 16, valid_loss: 0.015538422635903484\n",
            "updating best model on Fold=0\n",
            "EPOCH: 17, train_loss: 0.01589694745438611\n",
            "EPOCH: 17, valid_loss: 0.015420790222522459\n",
            "updating best model on Fold=0\n",
            "EPOCH: 18, train_loss: 0.015692988823124226\n",
            "EPOCH: 18, valid_loss: 0.015328903290394106\n",
            "updating best model on Fold=0\n",
            "EPOCH: 19, train_loss: 0.015499910752245244\n",
            "EPOCH: 19, valid_loss: 0.015214035630618272\n",
            "updating best model on Fold=0\n",
            "EPOCH: 20, train_loss: 0.015279485550302787\n",
            "EPOCH: 20, valid_loss: 0.015070443997453702\n",
            "updating best model on Fold=0\n",
            "EPOCH: 21, train_loss: 0.014996598743452322\n",
            "EPOCH: 21, valid_loss: 0.014988745440189776\n",
            "updating best model on Fold=0\n",
            "EPOCH: 22, train_loss: 0.014793222095042267\n",
            "EPOCH: 22, valid_loss: 0.014935594860856471\n",
            "updating best model on Fold=0\n",
            "EPOCH: 23, train_loss: 0.014669472664194619\n",
            "EPOCH: 23, valid_loss: 0.014918943867087364\n",
            "updating best model on Fold=0\n",
            "EPOCH: 24, train_loss: 0.014581322751239242\n",
            "EPOCH: 24, valid_loss: 0.014885375055631525\n",
            "updating best model on Fold=0\n",
            "None\n",
            "EPOCH: 0, train_loss: 0.5267399246460639\n",
            "EPOCH: 0, valid_loss: 0.029983662264911753\n",
            "updating best model on Fold=1\n",
            "EPOCH: 1, train_loss: 0.02212382295487711\n",
            "EPOCH: 1, valid_loss: 0.01891796952603679\n",
            "updating best model on Fold=1\n",
            "EPOCH: 2, train_loss: 0.018911049638768572\n",
            "EPOCH: 2, valid_loss: 0.01694652381794233\n",
            "updating best model on Fold=1\n",
            "EPOCH: 3, train_loss: 0.017628008493491068\n",
            "EPOCH: 3, valid_loss: 0.01660457432368084\n",
            "updating best model on Fold=1\n",
            "EPOCH: 4, train_loss: 0.016980913348945994\n",
            "EPOCH: 4, valid_loss: 0.016254180086482512\n",
            "updating best model on Fold=1\n",
            "EPOCH: 5, train_loss: 0.016640800951461265\n",
            "EPOCH: 5, valid_loss: 0.016154699370657142\n",
            "updating best model on Fold=1\n",
            "EPOCH: 6, train_loss: 0.016528386666420723\n",
            "EPOCH: 6, valid_loss: 0.015931249841263418\n",
            "updating best model on Fold=1\n",
            "EPOCH: 7, train_loss: 0.01641467633038359\n",
            "EPOCH: 7, valid_loss: 0.016098326072096825\n",
            "EPOCH: 8, train_loss: 0.01646308587151486\n",
            "EPOCH: 8, valid_loss: 0.016106299614827884\n",
            "EPOCH: 9, train_loss: 0.016417109738760347\n",
            "EPOCH: 9, valid_loss: 0.015928889257147125\n",
            "updating best model on Fold=1\n",
            "EPOCH: 10, train_loss: 0.016484065150104515\n",
            "EPOCH: 10, valid_loss: 0.01580846192021119\n",
            "updating best model on Fold=1\n",
            "EPOCH: 11, train_loss: 0.016419218553092654\n",
            "EPOCH: 11, valid_loss: 0.015887751096957607\n",
            "EPOCH: 12, train_loss: 0.01635785867153798\n",
            "EPOCH: 12, valid_loss: 0.015802983170081126\n",
            "updating best model on Fold=1\n",
            "EPOCH: 13, train_loss: 0.016315202272478367\n",
            "EPOCH: 13, valid_loss: 0.015793505296307176\n",
            "updating best model on Fold=1\n",
            "EPOCH: 14, train_loss: 0.016264268922175737\n",
            "EPOCH: 14, valid_loss: 0.01561915695569233\n",
            "updating best model on Fold=1\n",
            "EPOCH: 15, train_loss: 0.016163188951627522\n",
            "EPOCH: 15, valid_loss: 0.015806009943940137\n",
            "EPOCH: 16, train_loss: 0.016085580953915646\n",
            "EPOCH: 16, valid_loss: 0.015555762367225006\n",
            "updating best model on Fold=1\n",
            "EPOCH: 17, train_loss: 0.015882287955774156\n",
            "EPOCH: 17, valid_loss: 0.01539402670766178\n",
            "updating best model on Fold=1\n",
            "EPOCH: 18, train_loss: 0.015693310779463124\n",
            "EPOCH: 18, valid_loss: 0.01531574284461768\n",
            "updating best model on Fold=1\n",
            "EPOCH: 19, train_loss: 0.01545977048675886\n",
            "EPOCH: 19, valid_loss: 0.01517491682285541\n",
            "updating best model on Fold=1\n",
            "EPOCH: 20, train_loss: 0.01527170311884592\n",
            "EPOCH: 20, valid_loss: 0.015101406012514704\n",
            "updating best model on Fold=1\n",
            "EPOCH: 21, train_loss: 0.015025714481086938\n",
            "EPOCH: 21, valid_loss: 0.014976095751320062\n",
            "updating best model on Fold=1\n",
            "EPOCH: 22, train_loss: 0.01481669693685218\n",
            "EPOCH: 22, valid_loss: 0.014944135873137336\n",
            "updating best model on Fold=1\n",
            "EPOCH: 23, train_loss: 0.014643460493409794\n",
            "EPOCH: 23, valid_loss: 0.014898025185654038\n",
            "updating best model on Fold=1\n",
            "EPOCH: 24, train_loss: 0.014576257143994705\n",
            "EPOCH: 24, valid_loss: 0.014895418928445954\n",
            "updating best model on Fold=1\n",
            "None\n",
            "EPOCH: 0, train_loss: 0.5290741342926185\n",
            "EPOCH: 0, valid_loss: 0.029558952113515453\n",
            "updating best model on Fold=2\n",
            "EPOCH: 1, train_loss: 0.02182563084283931\n",
            "EPOCH: 1, valid_loss: 0.019715093419347938\n",
            "updating best model on Fold=2\n",
            "EPOCH: 2, train_loss: 0.018869948942189248\n",
            "EPOCH: 2, valid_loss: 0.017305696481152585\n",
            "updating best model on Fold=2\n",
            "EPOCH: 3, train_loss: 0.01754595743704762\n",
            "EPOCH: 3, valid_loss: 0.01688195502777633\n",
            "updating best model on Fold=2\n",
            "EPOCH: 4, train_loss: 0.01689131186662504\n",
            "EPOCH: 4, valid_loss: 0.016541476508504467\n",
            "updating best model on Fold=2\n",
            "EPOCH: 5, train_loss: 0.01659246335968675\n",
            "EPOCH: 5, valid_loss: 0.01628891079637565\n",
            "updating best model on Fold=2\n",
            "EPOCH: 6, train_loss: 0.016395383876992152\n",
            "EPOCH: 6, valid_loss: 0.016247197103343512\n",
            "updating best model on Fold=2\n",
            "EPOCH: 7, train_loss: 0.01642515906601544\n",
            "EPOCH: 7, valid_loss: 0.016650857109772533\n",
            "EPOCH: 8, train_loss: 0.016431657941199388\n",
            "EPOCH: 8, valid_loss: 0.016524277308857756\n",
            "EPOCH: 9, train_loss: 0.01642578184579643\n",
            "EPOCH: 9, valid_loss: 0.01648458855618772\n",
            "EPOCH: 10, train_loss: 0.016447182025935425\n",
            "EPOCH: 10, valid_loss: 0.016388556748432547\n",
            "EPOCH: 11, train_loss: 0.016416416359727813\n",
            "EPOCH: 11, valid_loss: 0.016219978098218377\n",
            "updating best model on Fold=2\n",
            "EPOCH: 12, train_loss: 0.016287886775129993\n",
            "EPOCH: 12, valid_loss: 0.01623586621625643\n",
            "EPOCH: 13, train_loss: 0.016307345066444587\n",
            "EPOCH: 13, valid_loss: 0.016300431918352842\n",
            "EPOCH: 14, train_loss: 0.016231079342081244\n",
            "EPOCH: 14, valid_loss: 0.01618923553216614\n",
            "updating best model on Fold=2\n",
            "EPOCH: 15, train_loss: 0.016065739195218823\n",
            "EPOCH: 15, valid_loss: 0.016145610667176936\n",
            "updating best model on Fold=2\n",
            "EPOCH: 16, train_loss: 0.01596319916089309\n",
            "EPOCH: 16, valid_loss: 0.015916601926284402\n",
            "updating best model on Fold=2\n",
            "EPOCH: 17, train_loss: 0.015807312219434936\n",
            "EPOCH: 17, valid_loss: 0.015762153179629854\n",
            "updating best model on Fold=2\n",
            "EPOCH: 18, train_loss: 0.015594386351888612\n",
            "EPOCH: 18, valid_loss: 0.015616379825300291\n",
            "updating best model on Fold=2\n",
            "EPOCH: 19, train_loss: 0.015432938952123958\n",
            "EPOCH: 19, valid_loss: 0.015518393514579848\n",
            "updating best model on Fold=2\n",
            "EPOCH: 20, train_loss: 0.015194651827016133\n",
            "EPOCH: 20, valid_loss: 0.015425418724158877\n",
            "updating best model on Fold=2\n",
            "EPOCH: 21, train_loss: 0.014966866051490675\n",
            "EPOCH: 21, valid_loss: 0.015320859212232264\n",
            "updating best model on Fold=2\n",
            "EPOCH: 22, train_loss: 0.014732428020078864\n",
            "EPOCH: 22, valid_loss: 0.01527201403912745\n",
            "updating best model on Fold=2\n",
            "EPOCH: 23, train_loss: 0.01462591430734868\n",
            "EPOCH: 23, valid_loss: 0.015225452248399196\n",
            "updating best model on Fold=2\n",
            "EPOCH: 24, train_loss: 0.014526459482192193\n",
            "EPOCH: 24, valid_loss: 0.015213929410827788\n",
            "updating best model on Fold=2\n",
            "None\n",
            "EPOCH: 0, train_loss: 0.5298131530566904\n",
            "EPOCH: 0, valid_loss: 0.027996761332217016\n",
            "updating best model on Fold=3\n",
            "EPOCH: 1, train_loss: 0.021585850932654117\n",
            "EPOCH: 1, valid_loss: 0.019370524947972673\n",
            "updating best model on Fold=3\n",
            "EPOCH: 2, train_loss: 0.018634313142439664\n",
            "EPOCH: 2, valid_loss: 0.01778318892282091\n",
            "updating best model on Fold=3\n",
            "EPOCH: 3, train_loss: 0.01744553407391646\n",
            "EPOCH: 3, valid_loss: 0.017198415203510148\n",
            "updating best model on Fold=3\n",
            "EPOCH: 4, train_loss: 0.016803470258944787\n",
            "EPOCH: 4, valid_loss: 0.016886719330949217\n",
            "updating best model on Fold=3\n",
            "EPOCH: 5, train_loss: 0.01655450730190781\n",
            "EPOCH: 5, valid_loss: 0.016749158673184484\n",
            "updating best model on Fold=3\n",
            "EPOCH: 6, train_loss: 0.01640929834879685\n",
            "EPOCH: 6, valid_loss: 0.016698030632381376\n",
            "updating best model on Fold=3\n",
            "EPOCH: 7, train_loss: 0.01645852706001309\n",
            "EPOCH: 7, valid_loss: 0.016562469156557007\n",
            "updating best model on Fold=3\n",
            "EPOCH: 8, train_loss: 0.01642831829970315\n",
            "EPOCH: 8, valid_loss: 0.01710237060232382\n",
            "EPOCH: 9, train_loss: 0.016412753811818642\n",
            "EPOCH: 9, valid_loss: 0.01655142795980761\n",
            "updating best model on Fold=3\n",
            "EPOCH: 10, train_loss: 0.01635544596477443\n",
            "EPOCH: 10, valid_loss: 0.016752397151369797\n",
            "EPOCH: 11, train_loss: 0.016318517355810875\n",
            "EPOCH: 11, valid_loss: 0.01668523448078256\n",
            "EPOCH: 12, train_loss: 0.016209987248450318\n",
            "EPOCH: 12, valid_loss: 0.016544206607106485\n",
            "updating best model on Fold=3\n",
            "EPOCH: 13, train_loss: 0.016245337421912073\n",
            "EPOCH: 13, valid_loss: 0.016390956717690353\n",
            "updating best model on Fold=3\n",
            "EPOCH: 14, train_loss: 0.016158948002395614\n",
            "EPOCH: 14, valid_loss: 0.016476865465703764\n",
            "EPOCH: 15, train_loss: 0.01602323430171549\n",
            "EPOCH: 15, valid_loss: 0.016384858613539683\n",
            "updating best model on Fold=3\n",
            "EPOCH: 16, train_loss: 0.015877660032636767\n",
            "EPOCH: 16, valid_loss: 0.01627914342833193\n",
            "updating best model on Fold=3\n",
            "EPOCH: 17, train_loss: 0.01572642343481315\n",
            "EPOCH: 17, valid_loss: 0.016035494345583413\n",
            "updating best model on Fold=3\n",
            "EPOCH: 18, train_loss: 0.015571780821571015\n",
            "EPOCH: 18, valid_loss: 0.016033867472096494\n",
            "updating best model on Fold=3\n",
            "EPOCH: 19, train_loss: 0.015383960566664702\n",
            "EPOCH: 19, valid_loss: 0.015866576865511507\n",
            "updating best model on Fold=3\n",
            "EPOCH: 20, train_loss: 0.015124689568859219\n",
            "EPOCH: 20, valid_loss: 0.015817130352125355\n",
            "updating best model on Fold=3\n",
            "EPOCH: 21, train_loss: 0.01491914516402371\n",
            "EPOCH: 21, valid_loss: 0.015655685412256343\n",
            "updating best model on Fold=3\n",
            "EPOCH: 22, train_loss: 0.014719965411412636\n",
            "EPOCH: 22, valid_loss: 0.015589996633168898\n",
            "updating best model on Fold=3\n",
            "EPOCH: 23, train_loss: 0.014518594919335123\n",
            "EPOCH: 23, valid_loss: 0.01556459544716697\n",
            "updating best model on Fold=3\n",
            "EPOCH: 24, train_loss: 0.014467307466438553\n",
            "EPOCH: 24, valid_loss: 0.015555481745028183\n",
            "updating best model on Fold=3\n",
            "None\n",
            "EPOCH: 0, train_loss: 0.5260646403610907\n",
            "EPOCH: 0, valid_loss: 0.028304938521040112\n",
            "updating best model on Fold=4\n",
            "EPOCH: 1, train_loss: 0.022006384903352532\n",
            "EPOCH: 1, valid_loss: 0.01963715279768956\n",
            "updating best model on Fold=4\n",
            "EPOCH: 2, train_loss: 0.018642993862646937\n",
            "EPOCH: 2, valid_loss: 0.01805361343155566\n",
            "updating best model on Fold=4\n",
            "EPOCH: 3, train_loss: 0.0173490285910916\n",
            "EPOCH: 3, valid_loss: 0.017143037660341514\n",
            "updating best model on Fold=4\n",
            "EPOCH: 4, train_loss: 0.016860953794679785\n",
            "EPOCH: 4, valid_loss: 0.016569314500022875\n",
            "updating best model on Fold=4\n",
            "EPOCH: 5, train_loss: 0.016593046161352386\n",
            "EPOCH: 5, valid_loss: 0.016553159460033242\n",
            "updating best model on Fold=4\n",
            "EPOCH: 6, train_loss: 0.016435002570584317\n",
            "EPOCH: 6, valid_loss: 0.01645462050739872\n",
            "updating best model on Fold=4\n",
            "EPOCH: 7, train_loss: 0.01640782447769338\n",
            "EPOCH: 7, valid_loss: 0.01648883896536733\n",
            "EPOCH: 8, train_loss: 0.016447956992575785\n",
            "EPOCH: 8, valid_loss: 0.016572044378048496\n",
            "EPOCH: 9, train_loss: 0.01644899339208867\n",
            "EPOCH: 9, valid_loss: 0.016556184714365946\n",
            "EPOCH: 10, train_loss: 0.016479967568294715\n",
            "EPOCH: 10, valid_loss: 0.01633761325655015\n",
            "updating best model on Fold=4\n",
            "EPOCH: 11, train_loss: 0.016416892178056624\n",
            "EPOCH: 11, valid_loss: 0.016270516072645\n",
            "updating best model on Fold=4\n",
            "EPOCH: 12, train_loss: 0.01634306890027435\n",
            "EPOCH: 12, valid_loss: 0.016264206974914198\n",
            "updating best model on Fold=4\n",
            "EPOCH: 13, train_loss: 0.016244581881785552\n",
            "EPOCH: 13, valid_loss: 0.01629085824089615\n",
            "EPOCH: 14, train_loss: 0.016199271550914586\n",
            "EPOCH: 14, valid_loss: 0.01619141879736593\n",
            "updating best model on Fold=4\n",
            "EPOCH: 15, train_loss: 0.016107619052515332\n",
            "EPOCH: 15, valid_loss: 0.016149627412424275\n",
            "updating best model on Fold=4\n",
            "EPOCH: 16, train_loss: 0.015946882170618782\n",
            "EPOCH: 16, valid_loss: 0.016031843365023012\n",
            "updating best model on Fold=4\n",
            "EPOCH: 17, train_loss: 0.015818757123795133\n",
            "EPOCH: 17, valid_loss: 0.01585821030465396\n",
            "updating best model on Fold=4\n",
            "EPOCH: 18, train_loss: 0.015696817721496493\n",
            "EPOCH: 18, valid_loss: 0.01574452861065143\n",
            "updating best model on Fold=4\n",
            "EPOCH: 19, train_loss: 0.015488021632018905\n",
            "EPOCH: 19, valid_loss: 0.015602779427641317\n",
            "updating best model on Fold=4\n",
            "EPOCH: 20, train_loss: 0.0152232086648477\n",
            "EPOCH: 20, valid_loss: 0.015536190329217598\n",
            "updating best model on Fold=4\n",
            "EPOCH: 21, train_loss: 0.015022250992439737\n",
            "EPOCH: 21, valid_loss: 0.015376907797824396\n",
            "updating best model on Fold=4\n",
            "EPOCH: 22, train_loss: 0.014825807171779991\n",
            "EPOCH: 22, valid_loss: 0.015369373814840066\n",
            "updating best model on Fold=4\n",
            "EPOCH: 23, train_loss: 0.014659531833291453\n",
            "EPOCH: 23, valid_loss: 0.01529725925310662\n",
            "updating best model on Fold=4\n",
            "EPOCH: 24, train_loss: 0.014639163352299056\n",
            "EPOCH: 24, valid_loss: 0.015282947766153436\n",
            "updating best model on Fold=4\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-4LGaxQavka",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "f4304b17-e869-40e3-d460-4e59097a4ef8"
      },
      "source": [
        "model = Model(\n",
        "    num_features=num_features,\n",
        "    num_targets=num_targets,\n",
        "    hidden_size=hidden_size,\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(f\"FOLD{fold}_.pth\"))           # Em qual model vamos fazer o predict? Ou vamos fazer a mean?\n",
        "model.to(DEVICE)\n",
        "\n",
        "test_df = process_data(test)\n",
        "x_test  = test_df[feature_cols].values\n",
        "test_dataset = TestDataset(x_test)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset)          # Notar que nao criamos batches\n",
        "\n",
        "def inference_fn(model, dataloader, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    \n",
        "    for data in dataloader:\n",
        "        inputs = data['x'].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "        \n",
        "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
        "        \n",
        "    preds = np.concatenate(preds)\n",
        "    \n",
        "    return preds\n",
        "\n",
        "predictions = np.zeros((len(test_df), target.iloc[:, 1:].shape[1]))\n",
        "predictions = inference_fn(model, testloader, DEVICE)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0aad399d4133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-0aad399d4133>\u001b[0m in \u001b[0;36minference_fn\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-9589e8c69f82>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0m_global_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 self._forward_pre_hooks.values()):\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/weight_norm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, module, inputs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/utils/weight_norm.py\u001b[0m in \u001b[0;36mcompute_weight\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_weight_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_g9DA4RYwgV"
      },
      "source": [
        "sample_submission = pd.read_csv('/content/drive/My Drive/moa/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GzfJHx8feli"
      },
      "source": [
        "y = pd.DataFrame(data=predictions)\n",
        "y.columns = target_cols\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ3ChHg1YyUc"
      },
      "source": [
        "sub = sample_submission.drop(columns=target_cols)\n",
        "frames = [sub, y]\n",
        "sub = pd.concat(frames, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdBp-IL_W2sJ"
      },
      "source": [
        "submission = sub.to_csv(\"submission.csv\",index=False)\n",
        "teste = pd.read_csv(\"submission.csv\")\n",
        "teste"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}